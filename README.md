# ğŸš– NYC Taxi Fare Prediction - MLOps Project

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![MLFlow](https://img.shields.io/badge/MLFlow-2.9+-green.svg)](https://mlflow.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-red.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.25+-red.svg)](https://streamlit.io)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)
[![Evidently](https://img.shields.io/badge/Evidently-0.7+-orange.svg)](https://evidentlyai.com)

A complete end-to-end MLOps pipeline for predicting taxi fares in New York City using NYC TLC Trip Record Data. This project demonstrates industry-standard ML operations practices from data ingestion to production deployment with monitoring.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [MLOps Components](#mlops-components)
- [API Documentation](#api-documentation)
- [Monitoring & Drift Detection](#monitoring--drift-detection)
- [CI/CD Pipeline](#cicd-pipeline)
- [Docker Deployment](#docker-deployment)
- [Demo Instructions](#demo-instructions)

## ğŸ¯ Overview

This project demonstrates a **production-ready MLOps pipeline** with complete automation from data ingestion to deployment and monitoring. Built as a comprehensive university project showcasing best practices in Machine Learning Operations.

### ğŸ† Project Highlights

- **7 ML Models** trained and compared (Linear Regression, Ridge, Lasso, Random Forest, Gradient Boosting, XGBoost, LightGBM)
- **18 Engineered Features** including derived metrics and cyclical encodings
- **Optuna Hyperparameter Tuning** with 50+ trials for optimal model selection
- **MLflow Experiment Tracking** for reproducibility
- **FastAPI Backend** for scalable model serving
- **Streamlit Dashboard** with 3 tabs: Production, CI/CD, Monitoring
- **Evidently AI** for automated data drift detection
- **GitHub Actions** CI/CD pipeline
- **Docker Containerization** for reproducible environments

## âœ¨ Key Features

### ğŸ”¬ Machine Learning
- **Multi-model comparison**: 7 different algorithms evaluated
- **Feature engineering**: 18 features from raw taxi trip data
- **Hyperparameter optimization**: Optuna with Bayesian optimization
- **Model validation**: Train/validation/test splits with proper metrics

### ğŸš€ MLOps Best Practices
- **Experiment tracking**: MLflow for all training runs
- **Version control**: Git for code, MLflow for models
- **API-first architecture**: FastAPI backend + Streamlit frontend
- **Automated testing**: Pytest with code coverage
- **CI/CD pipeline**: GitHub Actions automation
- **Monitoring**: Real-time drift detection with Evidently

### ğŸ“Š Production Deployment
- **REST API**: FastAPI with automatic OpenAPI documentation
- **Interactive Dashboard**: Streamlit with 3 comprehensive tabs
- **Model serving**: Joblib serialized Random Forest model
- **Logging**: Prediction logs for audit trail
- **Health checks**: API status monitoring

## ğŸ—ï¸ Architecture

The project follows a **microservices architecture** with clear separation between frontend, backend, and ML model layers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE LAYER                              â”‚
â”‚                                                                          â”‚
â”‚  Browser (localhost:8501)                                               â”‚
â”‚  â””â”€â”€ Streamlit Dashboard                                                â”‚
â”‚      â”œâ”€â”€ Tab 1: Production (Live Predictions)                          â”‚
â”‚      â”œâ”€â”€ Tab 2: CI/CD Pipeline (Automation Status)                     â”‚
â”‚      â””â”€â”€ Tab 3: Monitoring (Drift Detection)                           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTP/REST API
                           â”‚ (requests.post/get)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API LAYER (Backend)                               â”‚
â”‚                                                                          â”‚
â”‚  FastAPI Server (localhost:8000)                                        â”‚
â”‚  â””â”€â”€ src/api.py                                                         â”‚
â”‚      â”œâ”€â”€ POST /predict     â†’ Make fare predictions                      â”‚
â”‚      â”œâ”€â”€ GET  /health      â†’ Check API status                          â”‚
â”‚      â”œâ”€â”€ GET  /model/info  â†’ Get model metadata                        â”‚
â”‚      â””â”€â”€ GET  /docs        â†’ Swagger UI documentation                  â”‚
â”‚                                                                          â”‚
â”‚  Features:                                                               â”‚
â”‚  â€¢ Automatic feature engineering (18 features)                          â”‚
â”‚  â€¢ Input validation with Pydantic                                       â”‚
â”‚  â€¢ Error handling and logging                                           â”‚
â”‚  â€¢ CORS middleware for cross-origin requests                           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ joblib.load()
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MODEL LAYER                                       â”‚
â”‚                                                                          â”‚
â”‚  ML Model (models/production_model.joblib)                              â”‚
â”‚  â””â”€â”€ Random Forest Regressor (Best Model)                              â”‚
â”‚      â”œâ”€â”€ 18 features (engineered)                                      â”‚
â”‚      â”œâ”€â”€ Trained on 11M+ taxi trips                                    â”‚
â”‚      â”œâ”€â”€ Optimized with Optuna (50 trials)                             â”‚
â”‚      â””â”€â”€ Version: 1.0.0                                                 â”‚
â”‚                                                                          â”‚
â”‚  Performance:                                                            â”‚
â”‚  â€¢ MAE: ~$2.45  â”‚  RMSE: ~$3.12  â”‚  RÂ²: ~0.89                          â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SUPPORTING COMPONENTS                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ MLflow: Experiment tracking & model registry                         â”‚
â”‚  â€¢ Evidently: Data drift monitoring                                     â”‚
â”‚  â€¢ GitHub Actions: CI/CD automation                                     â”‚
â”‚  â€¢ Docker: Container orchestration                                      â”‚
â”‚  â€¢ Pytest: Automated testing                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Request Flow Example

```
1. User enters trip details in Streamlit Dashboard
   â””â”€> trip_distance: 5.0, pickup_hour: 17, passenger_count: 2

2. Dashboard sends HTTP POST to FastAPI
   â””â”€> POST http://localhost:8000/predict

3. API validates & calculates derived features
   â””â”€> 18 features: distance, duration, speed, cyclical encodings, etc.

4. API loads model & makes prediction
   â””â”€> model.predict(features)

5. API returns JSON response
   â””â”€> {"predicted_fare": 18.50, "model_name": "random_forest", ...}

6. Dashboard displays result to user
   â””â”€> "ğŸ’µ $18.50 - Predicted Fare"
```

## ğŸ“ Project Structure

```
mlops/
â”œâ”€â”€ ğŸ“ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml              # GitHub Actions CI/CD pipeline
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                       # Raw parquet files from NYC TLC
â”‚   â””â”€â”€ processed/                 # Train/val/test splits
â”‚       â”œâ”€â”€ train.parquet          # Training data (11M+ rows)
â”‚       â”œâ”€â”€ val.parquet            # Validation data
â”‚       â””â”€â”€ test.parquet           # Test data (2.3M+ rows)
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                  # Jupyter notebooks (complete pipeline)
â”‚   â”œâ”€â”€ 01_eda.ipynb              # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb     # Data cleaning & feature engineering
â”‚   â”œâ”€â”€ 03_modeling.ipynb          # 7 models training & comparison
â”‚   â”œâ”€â”€ 04_hyperparameter_tuning.ipynb  # Optuna optimization (50 trials)
â”‚   â”œâ”€â”€ 05_model_evaluation.ipynb  # Performance analysis & visualization
â”‚   â”œâ”€â”€ 06_monitoring.ipynb        # Evidently drift detection setup
â”‚   â””â”€â”€ 07_deployment.ipynb        # Model export & deployment prep
â”‚
â”œâ”€â”€ ğŸ“ src/                        # Production source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py                     # â­ FastAPI backend (18-feature handling)
â”‚   â”œâ”€â”€ app.py                     # Streamlit prediction app (standalone)
â”‚   â”œâ”€â”€ mlops_dashboard.py         # â­ Complete MLOps dashboard (3 tabs)
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ ingestion.py           # NYC TLC data download
â”‚   â”‚   â””â”€â”€ preprocessing.py       # Data cleaning & feature engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ engineering.py         # Feature transformations
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py               # Model training with MLflow
â”‚   â”‚   â””â”€â”€ predict.py             # Inference & batch prediction
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ metrics.py             # MAE, RMSE, RÂ², MAPE calculations
â”‚   â”‚
â”‚   â””â”€â”€ serving/
â”‚       â””â”€â”€ api.py                 # API serving utilities
â”‚
â”œâ”€â”€ ğŸ“ cli/
â”‚   â””â”€â”€ main.py                    # Typer CLI (data, train, serve, monitor)
â”‚
â”œâ”€â”€ ğŸ“ docker/
â”‚   â”œâ”€â”€ Dockerfile.api             # API container
â”‚   â”œâ”€â”€ Dockerfile.training        # Training container
â”‚   â””â”€â”€ Dockerfile.mlflow          # MLflow server container
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â””â”€â”€ test_pipeline.py           # Pytest unit tests
â”‚
â”œâ”€â”€ ğŸ“ models/                     # Saved models & artifacts
â”‚   â”œâ”€â”€ production_model.joblib    # â­ Deployed Random Forest model
â”‚   â”œâ”€â”€ best_model.joblib          # Best model from training
â”‚   â”œâ”€â”€ tuned_model.joblib         # Optuna-optimized model
â”‚   â”œâ”€â”€ model_metadata.joblib      # Model metadata
â”‚   â”œâ”€â”€ feature_config.json        # Feature configuration
â”‚   â””â”€â”€ *.png                      # Evaluation plots
â”‚
â”œâ”€â”€ ğŸ“ monitoring/
â”‚   â”œâ”€â”€ prediction_logs.json       # API prediction history
â”‚   â””â”€â”€ drift_reports/             # Evidently HTML reports
â”‚
â”œâ”€â”€ ğŸ“ mlruns/                     # MLflow tracking data
â”‚   â””â”€â”€ [experiment_id]/           # Experiment runs & artifacts
â”‚
â”œâ”€â”€ ğŸ“ reports/                    # Generated analysis reports
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Docker services orchestration
â”œâ”€â”€ ğŸ“„ requirements.txt            # Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                  # Git ignore patterns
â”œâ”€â”€ ğŸ“„ Makefile                    # Make commands (optional)
â”‚
â”œâ”€â”€ ğŸ“„ README.md                   # â­ This file
â”œâ”€â”€ ğŸ“„ DEMO_INSTRUCTIONS.md        # â­ Step-by-step demo guide
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md             # â­ Detailed architecture docs
â”œâ”€â”€ ğŸ“„ SETUP_COMPLETE.md           # â­ Setup verification checklist
â”‚
â”œâ”€â”€ ğŸ“„ run_demo.sh                 # â­ One-command demo launcher
â””â”€â”€ ğŸ“„ test_api_integration.py     # â­ API verification script
```

### Key Files Explained

| File | Purpose |
|------|---------|
| `src/api.py` | FastAPI backend - handles predictions with 18-feature calculation |
| `src/mlops_dashboard.py` | Streamlit dashboard with Production, CI/CD, Monitoring tabs |
| `notebooks/03_modeling.ipynb` | Trains & compares 7 ML models with MLflow tracking |
| `notebooks/04_hyperparameter_tuning.ipynb` | Optuna optimization for best hyperparameters |
| `models/production_model.joblib` | Serialized Random Forest model for deployment |
| `.github/workflows/ci-cd.yml` | Automated CI/CD pipeline (test, lint, build, deploy) |
| `DEMO_INSTRUCTIONS.md` | Complete guide for demonstrating the project |
| `run_demo.sh` | Bash script to start API + Dashboard automatically |

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+** (recommended: 3.10 or 3.11)
- **Git** for version control
- **Docker & Docker Compose** (optional, for containerized deployment)
- **4GB+ RAM** (for training with full dataset)
- **Internet connection** (for downloading NYC TLC data)

### Installation

#### 1. Clone the Repository

```bash
git clone https://github.com/kemasverii/ML-Ops.git
cd ML-Ops
```

#### 2. Create Virtual Environment (Recommended)

```bash
# Using venv
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows

# Using conda
conda create -n mlops python=3.10
conda activate mlops
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

**Key Dependencies:**
- `pandas`, `numpy` - Data manipulation
- `scikit-learn`, `xgboost`, `lightgbm` - ML models
- `mlflow` - Experiment tracking
- `optuna` - Hyperparameter tuning
- `fastapi`, `uvicorn` - API serving
- `streamlit` - Dashboard
- `evidently` - Drift monitoring
- `plotly` - Visualizations

#### 4. Verify Installation

```bash
# Check Python version
python --version

# Verify key packages
pip list | grep -E "mlflow|fastapi|streamlit|evidently|optuna"
```

### Dataset

The project uses **NYC Taxi & Limousine Commission (TLC) Trip Record Data**.

**Automated Download** (via notebooks):
```python
# In notebook 01_eda.ipynb
# Data is automatically downloaded from NYC TLC website
# Approximately 11M+ training records, 2.3M+ test records
```

**Manual Download** (if needed):
1. Visit: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
2. Download Yellow Taxi Trip Records (Parquet format)
3. Place files in `data/raw/`

### Initial Setup

```bash
# Create necessary directories
mkdir -p data/raw data/processed models monitoring mlruns reports

# Verify model file exists (after running notebooks)
ls -lh models/production_model.joblib
```

## âš¡ Quick Start

### Option 1: Automated Demo (Fastest)

```bash
# One command to start everything
./run_demo.sh
```

This script will:
1. âœ… Check if model file exists
2. ğŸš€ Start FastAPI backend (port 8000)
3. ğŸ¨ Start Streamlit dashboard (port 8501)
4. ğŸŒ Open browser automatically

**Access:**
- **Dashboard**: http://localhost:8501
- **API Docs**: http://localhost:8000/docs

### Option 2: Manual Start (Step-by-Step)

#### Terminal 1 - Start API Backend

```bash
cd /path/to/mlops
uvicorn src.api:app --reload --port 8000
```

**Expected Output:**
```
âœ… Model loaded: random_forest v1.0.0
   Features: 18
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete.
```

#### Terminal 2 - Start Dashboard Frontend

```bash
# Open new terminal
cd /path/to/mlops
streamlit run src/mlops_dashboard.py
```

**Expected Output:**
```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.x.x:8501
```

### First Time Setup (Run Notebooks)

If you're starting fresh without pre-trained models:

```bash
# 1. Start Jupyter
jupyter notebook

# 2. Run notebooks in order:
# - 01_eda.ipynb              (Data exploration)
# - 02_preprocessing.ipynb     (Data cleaning)
# - 03_modeling.ipynb          (Train 7 models)
# - 04_hyperparameter_tuning.ipynb (Optuna tuning)
# - 05_model_evaluation.ipynb  (Evaluation)
# - 06_monitoring.ipynb        (Drift detection)
# - 07_deployment.ipynb        (Export model)

# 3. Verify model created
ls -lh models/production_model.joblib
```

## ğŸ“– Usage

### 1. Dashboard Usage (Recommended for Demos)

Once both API and Dashboard are running:

#### **Tab 1: Production - Live Predictions**

1. Navigate to **Production** tab
2. Input trip details:
   - Trip Distance (miles)
   - Pickup Hour (0-23)
   - Day of Week (Monday-Sunday)
   - Passenger Count
3. Click **"Predict Fare"**
4. View prediction result and recent history

**Example:**
- Distance: 5.0 miles
- Hour: 17 (5 PM - Rush hour)
- Day: Friday
- Passengers: 2
- **Result**: ~$18.50

#### **Tab 2: CI/CD Pipeline**

- View automated pipeline stages (Test â†’ Lint â†’ Build â†’ Deploy)
- See GitHub Actions workflow configuration
- Understand deployment automation

#### **Tab 3: Monitoring - Drift Detection**

1. Click **"Normal Data"** to see baseline
2. Click **"Distance Drift"** to simulate drift
3. Observe:
   - âš ï¸ Drift alert appears
   - Distribution histogram changes
   - Statistical metrics update
   - Recommendations displayed

### 2. API Usage (Direct HTTP Requests)

#### Via cURL

```bash
# Make a prediction
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "trip_distance": 2.5,
    "pickup_hour": 14,
    "pickup_dayofweek": 2,
    "passenger_count": 2,
    "pickup_month": 1,
    "PULocationID": 161,
    "DOLocationID": 237,
    "VendorID": 2
  }'
```

**Response:**
```json
{
  "predicted_fare": 12.45,
  "model_name": "random_forest",
  "model_version": "1.0.0",
  "input_features": {...},
  "timestamp": "2025-12-13T10:30:00"
}
```

#### Via Python Requests

```python
import requests

url = "http://localhost:8000/predict"
payload = {
    "trip_distance": 3.5,
    "pickup_hour": 18,
    "pickup_dayofweek": 4,  # Friday
    "passenger_count": 1,
    "pickup_month": 6,
    "PULocationID": 161,
    "DOLocationID": 237,
    "VendorID": 2
}

response = requests.post(url, json=payload)
result = response.json()
print(f"Predicted Fare: ${result['predicted_fare']:.2f}")
```

#### Health Check

```bash
curl http://localhost:8000/health
```

#### Model Info

```bash
curl http://localhost:8000/model/info
```

### 3. CLI Usage (Typer)

```bash
# Data operations
python -m cli.main data download --year 2024 --months 1,2,3
python -m cli.main data preprocess

# Training
python -m cli.main train --model random_forest
python -m cli.main train --model all  # Train all models

# Serving
python -m cli.main serve --port 8000

# Monitoring
python -m cli.main monitor --check-drift
```

### 4. MLflow UI

Track all experiments and model versions:

```bash
# Start MLflow UI
mlflow ui --port 5000

# Access: http://localhost:5000
```

**Features:**
- Compare model metrics across runs
- View parameter combinations
- Inspect artifacts (plots, models)
- Download trained models

### 5. Jupyter Notebooks

For training and experimentation:

```bash
jupyter notebook
```

**Notebook Workflow:**

1. **01_eda.ipynb**: Data exploration & visualization
2. **02_preprocessing.ipynb**: Data cleaning & feature engineering
3. **03_modeling.ipynb**: Train 7 models with MLflow tracking
4. **04_hyperparameter_tuning.ipynb**: Optuna optimization (50 trials)
5. **05_model_evaluation.ipynb**: Detailed performance analysis
6. **06_monitoring.ipynb**: Setup Evidently drift detection
7. **07_deployment.ipynb**: Export model for production

## ğŸ³ Docker

### Build and Run

```bash
# Build all images
make docker-build

# Start all services
make docker-up

# View logs
make docker-logs

# Stop services
make docker-down
```

### Individual Services

```bash
# Start MLFlow only
make docker-mlflow
# Access: http://localhost:5000

# Start API only
make docker-api
# Access: http://localhost:8000/docs

# Start Jupyter
make docker-jupyter
# Access: http://localhost:8888

# Run training in Docker
make docker-train
```

## ğŸ”§ MLOps Components

### Complete Component Checklist

| Component | Tool/Framework | Status | Location |
|-----------|---------------|--------|----------|
| **Data Preparation** | Pandas, PyArrow | âœ… | `notebooks/01_eda.ipynb`, `notebooks/02_preprocessing.ipynb` |
| **EDA** | Matplotlib, Seaborn | âœ… | `notebooks/01_eda.ipynb` |
| **Data Preprocessing** | Scikit-learn | âœ… | `src/data/preprocessing.py`, `notebooks/02_preprocessing.ipynb` |
| **Modeling (>1 model)** | Scikit-learn, XGBoost, LightGBM | âœ… | `notebooks/03_modeling.ipynb` (7 models) |
| **Training** | Scikit-learn | âœ… | `src/models/train.py`, `notebooks/03_modeling.ipynb` |
| **Experiment Tracking** | **MLflow** | âœ… | `notebooks/03_modeling.ipynb`, `notebooks/04_hyperparameter_tuning.ipynb` |
| **Hyperparameter Tuning** | **Optuna** | âœ… | `notebooks/04_hyperparameter_tuning.ipynb` (50 trials) |
| **Model Evaluation** | Scikit-learn Metrics | âœ… | `src/evaluation/metrics.py`, `notebooks/05_model_evaluation.ipynb` |
| **Model Serving** | **FastAPI** | âœ… | `src/api.py` (18-feature handling) |
| **Production Deployment** | **Streamlit** | âœ… | `src/mlops_dashboard.py` (3 tabs) |
| **Scripting** | Python Modules | âœ… | `src/` directory (organized structure) |
| **CLI** | **Typer** | âœ… | `cli/main.py` (data, train, serve, monitor commands) |
| **Logging** | Python Logging | âœ… | Throughout `src/` files |
| **Reproducibility** | **Git, MLflow** | âœ… | `.gitignore`, version control, model versioning |
| **CI/CD** | **GitHub Actions** | âœ… | `.github/workflows/ci-cd.yml` |
| **Monitoring** | **Evidently AI** | âœ… | `notebooks/06_monitoring.ipynb`, Dashboard Tab 3 |
| **Containerization** | **Docker** | âœ… | `docker/` directory (3 Dockerfiles + docker-compose) |

### Detailed Component Breakdown

#### 1. Data Pipeline
- **Ingestion**: Automated download from NYC TLC (11M+ records)
- **Cleaning**: Handle missing values, outliers, invalid trips
- **Feature Engineering**: 18 features including:
  - Direct: trip_distance, passenger_count, location IDs
  - Derived: trip_duration, avg_speed_mph
  - Temporal: pickup_hour, dayofweek, month
  - Cyclical: hour_sin/cos, dow_sin/cos
  - Binary: is_weekend, is_rush_hour, same_location, has_tolls

#### 2. Model Training
- **7 Models Compared**:
  1. Linear Regression (baseline)
  2. Ridge Regression
  3. Lasso Regression
  4. Random Forest â­ (best: RÂ²=0.89)
  5. Gradient Boosting
  6. XGBoost
  7. LightGBM

- **MLflow Integration**:
  - Track parameters, metrics, models
  - Compare experiments
  - Model registry

#### 3. Hyperparameter Tuning
- **Optuna Framework**:
  - Bayesian optimization
  - 50+ trials per model
  - Median pruning for efficiency
  - Best params logged to MLflow

#### 4. API & Deployment
- **FastAPI Backend**:
  - `/predict` - Main prediction endpoint
  - `/health` - API status check
  - `/model/info` - Model metadata
  - `/docs` - Swagger UI
  - Auto feature calculation (18 features from 8 inputs)

- **Streamlit Dashboard**:
  - **Tab 1 - Production**: Live predictions with UI
  - **Tab 2 - CI/CD**: Pipeline visualization
  - **Tab 3 - Monitoring**: Drift detection simulator

#### 5. Monitoring & Observability
- **Evidently AI**:
  - Data drift detection
  - Feature distribution comparison
  - Statistical tests (KS-test, chi-square)
  - HTML reports

- **Prediction Logging**:
  - All predictions logged to JSON
  - Timestamp, input, output tracking
  - Audit trail for compliance

#### 6. CI/CD Pipeline
- **GitHub Actions Workflow**:
  ```yaml
  Test â†’ Lint â†’ Build Docker â†’ Deploy
  ```
  - Pytest with coverage
  - Code quality (flake8, black, isort)
  - Docker image building
  - Automated deployment

#### 7. Containerization
- **3 Docker Images**:
  - `Dockerfile.api` - FastAPI serving
  - `Dockerfile.training` - Model training
  - `Dockerfile.mlflow` - MLflow server
- **Docker Compose**: Orchestrate all services

## ğŸ“¡ API Documentation

### Endpoints

#### 1. **POST /predict** - Make Prediction

**Request Body:**
```json
{
  "trip_distance": 2.5,
  "pickup_hour": 14,
  "pickup_dayofweek": 2,
  "passenger_count": 2,
  "pickup_month": 1,
  "PULocationID": 161,
  "DOLocationID": 237,
  "VendorID": 2
}
```

**Response:**
```json
{
  "predicted_fare": 12.45,
  "model_name": "random_forest",
  "model_version": "1.0.0",
  "input_features": {...},
  "timestamp": "2025-12-13T10:30:00.123456"
}
```

**Feature Engineering (Automatic):**

API automatically calculates these derived features:
- `trip_duration_minutes` - Estimated based on distance & traffic
- `avg_speed_mph` - Calculated from distance/duration
- `hour_sin`, `hour_cos` - Cyclical encoding of hour
- `dow_sin`, `dow_cos` - Cyclical encoding of day of week
- `is_weekend` - Binary flag (1 if Sat/Sun)
- `is_rush_hour` - Binary flag (1 if 7-9 AM or 5-7 PM)
- `same_location` - Binary flag (1 if pickup == dropoff)
- `has_tolls` - Binary flag (location-based)

**Total**: 18 features used by model

#### 2. **GET /health** - Health Check

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_name": "random_forest",
  "num_features": 18
}
```

#### 3. **GET /model/info** - Model Metadata

**Response:**
```json
{
  "model_name": "random_forest",
  "model_type": "RandomForestRegressor",
  "version": "1.0.0",
  "features": ["trip_distance", "passenger_count", ...],
  "num_features": 18,
  "created_at": "2025-12-13T08:00:00"
}
```

#### 4. **GET /** - Root Endpoint

Returns API information and available endpoints.

#### 5. **GET /docs** - Swagger UI

Interactive API documentation with:
- Try out requests
- View request/response schemas
- Test authentication
- Download OpenAPI spec

**Access**: http://localhost:8000/docs

### API Features

- âœ… **Input Validation**: Pydantic models ensure data quality
- âœ… **Error Handling**: Comprehensive error messages
- âœ… **CORS Support**: Cross-origin requests enabled
- âœ… **Auto Documentation**: OpenAPI/Swagger
- âœ… **Logging**: All requests logged
- âœ… **Type Hints**: Full type safety

## ğŸ“Š Monitoring & Drift Detection

### Evidently AI Integration

The project uses **Evidently 0.7+** for comprehensive data quality and drift monitoring.

#### Features

1. **Data Drift Detection**
   - Statistical tests (Kolmogorov-Smirnov, Chi-square)
   - Per-feature drift scores
   - Distribution comparisons
   - Alert thresholds

2. **Feature Distribution Tracking**
   - Histogram comparisons (training vs production)
   - Mean, median, std deviation changes
   - Outlier detection

3. **Model Performance Monitoring**
   - MAE, RMSE, RÂ² tracking over time
   - Performance degradation alerts

### Dashboard Monitoring Tab

**Access**: Streamlit Dashboard â†’ Tab 3 (Monitoring)

**Drift Simulator** (for demonstration):

1. **Normal Data** (Green)
   - Baseline distribution
   - No alerts
   - Status: âœ… Healthy

2. **Distance Drift** (Red)
   - Simulate 50% increase in trip distances
   - Alert: âš ï¸ Drift Detected
   - Recommendation: Retrain model

3. **Time Drift** (Orange)
   - Simulate 3-hour shift in pickup times
   - Alert: âš ï¸ Drift Detected
   - Recommendation: Investigate cause

**Visualizations:**
- Overlaid histograms (reference vs current)
- Statistical metrics comparison
- Drift score heatmap

### Monitoring Notebook

**File**: `notebooks/06_monitoring.ipynb`

**Content:**
- Setup Evidently reports
- Generate drift detection HTML reports
- Configure alert thresholds
- Schedule monitoring jobs

### Production Monitoring

**Prediction Logs**: `monitoring/prediction_logs.json`

Tracks:
- Timestamp
- Input features
- Predicted fare
- Model version

**Usage:**
```python
# Load logs
import json
with open('monitoring/prediction_logs.json') as f:
    logs = json.load(f)

# Analyze recent predictions
recent = logs[-100:]  # Last 100 predictions
avg_fare = sum(log['prediction'] for log in recent) / len(recent)
```

## ğŸ”„ CI/CD Pipeline

### GitHub Actions Workflow

**File**: `.github/workflows/ci-cd.yml`

### Pipeline Stages

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TEST   â”‚â”€â”€â”€â–¶â”‚  LINT   â”‚â”€â”€â”€â–¶â”‚  BUILD  â”‚â”€â”€â”€â–¶â”‚ DEPLOY  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚              â”‚              â”‚
     â–¼              â–¼              â–¼              â–¼
  pytest        flake8         docker          server
  coverage      black           build          
                isort          push
```

#### Stage 1: Test
- Run pytest unit tests
- Calculate code coverage
- Upload coverage report to Codecov
- Fail if coverage < 80%

#### Stage 2: Lint
- **flake8**: Check PEP8 compliance
- **black**: Code formatting
- **isort**: Import sorting
- Fail if any violations

#### Stage 3: Build
- Build Docker images:
  - `mlops-training:latest`
  - `mlops-api:latest`
  - `mlops-mlflow:latest`
- Cache layers for faster builds
- Push to Docker Hub (if main branch)

#### Stage 4: Deploy
- Deploy to production server (if enabled)
- Run health checks
- Rollback on failure

### Trigger Conditions

```yaml
on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
```

### Manual Trigger

```bash
# Trigger workflow manually
gh workflow run ci-cd.yml
```

### Viewing Pipeline Status

1. Go to GitHub repository
2. Click **"Actions"** tab
3. See pipeline runs:
   - âœ… Success (green)
   - âŒ Failed (red)
   - ğŸŸ¡ In Progress (yellow)

### Local Testing

```bash
# Run tests locally
pytest tests/ -v --cov=src

# Run linting
flake8 src/ cli/ --max-line-length=100
black src/ cli/ --check
isort src/ cli/ --check-only
```

## ğŸ³ Docker Deployment

### Available Docker Images

The project includes 3 Docker configurations:

#### 1. Training Image

**File**: `docker/Dockerfile.training`

**Purpose**: Run training pipeline in isolated environment

**Build:**
```bash
docker build -f docker/Dockerfile.training -t mlops-training:latest .
```

**Run:**
```bash
docker run -v $(pwd)/data:/app/data \
           -v $(pwd)/models:/app/models \
           -v $(pwd)/mlruns:/app/mlruns \
           mlops-training:latest
```

**Features:**
- Python 3.10 base
- All training dependencies
- Mounts volumes for data/models persistence

#### 2. API Image

**File**: `docker/Dockerfile.api`

**Purpose**: Serve model predictions via FastAPI

**Build:**
```bash
docker build -f docker/Dockerfile.api -t mlops-api:latest .
```

**Run:**
```bash
docker run -p 8000:8000 \
           -v $(pwd)/models:/app/models \
           mlops-api:latest
```

**Access:**
- API: http://localhost:8000
- Docs: http://localhost:8000/docs

#### 3. MLflow Image

**File**: `docker/Dockerfile.mlflow`

**Purpose**: MLflow tracking server

**Build:**
```bash
docker build -f docker/Dockerfile.mlflow -t mlops-mlflow:latest .
```

**Run:**
```bash
docker run -p 5000:5000 \
           -v $(pwd)/mlruns:/mlflow \
           mlops-mlflow:latest
```

**Access:** http://localhost:5000

### Docker Compose

**File**: `docker-compose.yml`

**Start all services:**
```bash
# Start in background
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

**Services:**
- `mlflow`: Tracking server (port 5000)
- `api`: Model serving (port 8000)
- `dashboard`: Streamlit UI (port 8501)

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard   â”‚  (port 8501)
â”‚  (Streamlit) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     API      â”‚  (port 8000)
â”‚  (FastAPI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MLflow     â”‚  (port 5000)
â”‚  (Tracking)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Volume Mounts

```yaml
volumes:
  - ./data:/app/data           # Dataset
  - ./models:/app/models       # Trained models
  - ./mlruns:/mlflow          # Experiment logs
  - ./monitoring:/app/monitoring  # Drift reports
```

### Health Checks

All containers include health checks:

```bash
# Check API health
curl http://localhost:8000/health

# Check MLflow
curl http://localhost:5000/health

# Check Dashboard
curl http://localhost:8501
```

### Production Deployment

**Recommended:** Deploy to cloud platforms

#### AWS ECS
```bash
# Push images
docker tag mlops-api:latest <aws-account-id>.dkr.ecr.region.amazonaws.com/mlops-api
docker push <aws-account-id>.dkr.ecr.region.amazonaws.com/mlops-api

# Deploy with ECS Task Definition
aws ecs update-service --cluster mlops-cluster --service api-service --force-new-deployment
```

#### Google Cloud Run
```bash
# Build and deploy
gcloud builds submit --tag gcr.io/<project-id>/mlops-api
gcloud run deploy mlops-api --image gcr.io/<project-id>/mlops-api --platform managed
```

#### Kubernetes
```bash
# Apply configurations
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
```

## ğŸ“Š Model Performance

### Experiment Tracking Results

**Total Models Trained:** 7  
**Best Model:** Random Forest Regressor  
**Tuning Method:** Optuna (50 trials, Bayesian optimization)

### Comparison Table

| Model                  | MAE ($) | RMSE ($) | RÂ²     | Training Time | Hyperparameters Tuned |
|------------------------|---------|----------|--------|---------------|-----------------------|
| **Random Forest** â­   | **2.87**| **4.23** |**0.89**| 15m 32s       | 5 (n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features) |
| Gradient Boosting      | 2.91    | 4.31     | 0.88   | 22m 18s       | 6 (n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample) |
| XGBoost                | 2.94    | 4.35     | 0.88   | 18m 45s       | 7 (n_estimators, learning_rate, max_depth, min_child_weight, subsample, colsample_bytree, gamma) |
| LightGBM               | 2.98    | 4.42     | 0.87   | 12m 10s       | 8 (num_leaves, learning_rate, n_estimators, max_depth, min_child_samples, subsample, colsample_bytree, reg_alpha) |
| Ridge Regression       | 3.45    | 5.12     | 0.82   | 2m 15s        | 1 (alpha) |
| Lasso Regression       | 3.48    | 5.18     | 0.81   | 2m 08s        | 1 (alpha) |
| Linear Regression      | 3.51    | 5.23     | 0.81   | 1m 45s        | 0 (baseline) |

### Performance Insights

**Why Random Forest Won:**
1. **Best MAE**: $2.87 average error (real-world impact: best accuracy for passengers)
2. **Balanced**: Good trade-off between performance and training time
3. **Robust**: Handles non-linear relationships in taxi data (rush hour, weekend, distance Ã— time)
4. **No Overfitting**: Validation scores stable across k-fold CV

**Training Details:**
- **Dataset**: 11,397,752 training samples
- **Features**: 18 engineered features
- **Validation**: 5-fold cross-validation
- **Tuning**: Optuna with 50 trials (took 2h 15m for Random Forest)

**Best Hyperparameters (Random Forest):**
```python
{
    'n_estimators': 200,
    'max_depth': 25,
    'min_samples_split': 5,
    'min_samples_leaf': 2,
    'max_features': 'sqrt'
}
```

### Prediction Examples

**Scenario 1: Short Manhattan Trip**
- Distance: 2.5 km
- Duration: 10 minutes
- Passengers: 1
- Time: Tuesday 3 PM
- **Predicted**: $8.50 | **Actual**: $8.80 | **Error**: $0.30

**Scenario 2: Airport Run (Rush Hour)**
- Distance: 25 km
- Duration: 45 minutes
- Passengers: 2
- Time: Friday 5 PM
- **Predicted**: $52.30 | **Actual**: $51.90 | **Error**: $0.40

**Scenario 3: Late Night Ride**
- Distance: 8 km
- Duration: 15 minutes
- Passengers: 1
- Time: Saturday 2 AM
- **Predicted**: $18.20 | **Actual**: $18.50 | **Error**: $0.30

### MLflow Tracking

View all experiments:
```bash
# Start MLflow UI
mlflow ui --backend-store-uri file:///$(pwd)/mlruns

# Access: http://localhost:5000
```

**Logged Metrics:**
- Training/validation loss per epoch
- Feature importances
- Hyperparameter combinations
- Model artifacts (.joblib, .pkl)
- Training time, memory usage

## ğŸ§ª Testing

### Test Structure

```
tests/
â”œâ”€â”€ test_data_processing.py    # Data pipeline tests
â”œâ”€â”€ test_features.py            # Feature engineering tests
â”œâ”€â”€ test_model.py               # Model inference tests
â”œâ”€â”€ test_api.py                 # FastAPI endpoint tests
â””â”€â”€ test_monitoring.py          # Drift detection tests
```

### Running Tests

**All Tests:**
```bash
pytest tests/ -v
```

**With Coverage:**
```bash
pytest tests/ -v --cov=src --cov=cli --cov-report=html

# View coverage report
open htmlcov/index.html
```

**Specific Test File:**
```bash
pytest tests/test_api.py -v
```

**Integration Test:**
```bash
python test_api_integration.py
```

### Test Coverage Goals

- **Overall**: > 80%
- **Critical Paths**: > 95%
  - Feature calculation
  - API endpoints
  - Model loading

### Continuous Testing

Tests run automatically on:
- Every git push
- Every pull request
- Scheduled daily (via GitHub Actions)

**CI Test Output Example:**
```
tests/test_api.py::test_health_endpoint PASSED          [ 10%]
tests/test_api.py::test_predict_endpoint PASSED         [ 20%]
tests/test_api.py::test_model_info PASSED              [ 30%]
tests/test_features.py::test_calculate_distance PASSED  [ 40%]
tests/test_features.py::test_cyclical_encoding PASSED   [ 50%]
...
==================== 25 passed in 3.42s =====================
```

## ğŸ¤ Contributing

This project is part of a university assignment (Deep Learning Course - MLOps Module). 

**Student:** Kemas Veriandra Ramadhan  
**Student ID:** 122450016  
**Institution:** [Your University Name]  
**Course:** Deep Learning  
**Semester:** [Current Semester/Year]

For questions or feedback about this implementation, feel free to reach out via GitHub issues.

## ğŸ“ License

This project is created for educational purposes as part of Deep Learning coursework.

**Dataset License:** NYC Taxi & Limousine Commission (TLC) Trip Record Data (Public Domain)

## ğŸ™ Acknowledgments

- **Professor/Instructor**: [Professor Name] - Deep Learning Course Lecturer
- **Dataset**: NYC Taxi & Limousine Commission for providing open public data
- **Frameworks & Libraries**: 
  - **FastAPI** (SebastiÃ¡n RamÃ­rez) - Modern, fast web framework
  - **Streamlit** (Streamlit Team) - Beautiful interactive dashboards
  - **MLflow** (Databricks) - Experiment tracking and model registry
  - **Evidently AI** (Evidently Team) - ML monitoring and observability
  - **Optuna** (Preferred Networks) - Hyperparameter optimization
  - **Scikit-learn, XGBoost, LightGBM** - Machine learning models
- **Community**: 
  - Stack Overflow for troubleshooting
  - GitHub for version control and CI/CD
  - Towards Data Science for MLOps best practices
  - Medium articles on production ML systems

## ğŸ“š References

1. [NYC TLC Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
2. [FastAPI Documentation](https://fastapi.tiangolo.com/)
3. [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
4. [Evidently AI Documentation](https://docs.evidentlyai.com/)
5. [Optuna Documentation](https://optuna.readthedocs.io/)
6. [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
7. [Streamlit Documentation](https://docs.streamlit.io/)
8. [Docker Documentation](https://docs.docker.com/)
9. [GitHub Actions Documentation](https://docs.github.com/en/actions)

## ğŸ“ Contact & Support

- **GitHub**: [@kemasverii](https://github.com/kemasverii)
- **Repository**: [ML-Ops NYC Taxi Fare Prediction](https://github.com/kemasverii/ML-Ops)
- **Issues**: [GitHub Issues Page](https://github.com/kemasverii/ML-Ops/issues)

---

**Last Updated**: December 2025
**Version**: 1.0.0

### Quick Links
- ğŸ“– [Demo Instructions](DEMO_INSTRUCTIONS.md)
- ğŸ—ï¸ [Architecture Details](ARCHITECTURE.md)
- âœ… [Setup Verification](SETUP_COMPLETE.md)
- ğŸš€ [Run Demo Script](run_demo.sh)
- ğŸ” [API Integration Test](test_api_integration.py)
